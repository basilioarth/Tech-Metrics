# Resumo da Aula: Observabilidade e Confiabilidade

## Introdução
A aula aborda observabilidade e confiabilidade em sistemas de software, com foco em métricas que garantem a estabilidade e permitem respostas rápidas a incidentes. O professor explora os quatro pilares da observabilidade (*golden signals*, logs, traces e alertas), explica conceitos como SLI, SLO e SLA, e destaca a importância de monitorar o que impacta o usuário final. Exemplos de empresas como Amazon, Uber e Spotify ilustram a aplicação prática, junto com ferramentas e passos para implementar um sistema robusto que minimize *downtime* e melhore a experiência do usuário.

## Importância da Observabilidade e Confiabilidade
- **Contexto**: Incidentes, como sistemas fora do ar às 3h da manhã, exigem respostas rápidas. Observabilidade permite identificar e resolver problemas rapidamente, garantindo *predictability*.
- **Custo do Downtime**: 
  - 99,9% de *uptime* permite até 8h45min de indisponibilidade por ano.
  - 99,99% reduz isso para 52 minutos, destacando a importância de cada "9" na disponibilidade.
- **Impacto Financeiro**: Na Amazon, cada 100ms de latência reduz a conversão em 1%, representando perdas significativas.

## Quatro Pilares da Observabilidade
O professor detalha os quatro pilares fundamentais para monitorar sistemas:
1. **Métricas (Golden Signals)**:
   - **Latência**: Tempo de resposta (ex.: P95 < 200ms para 95% das requisições). Crucial para desempenho, como no caso da Amazon.
   - **Tráfego**: Requisições por segundo (RPS), indicando a capacidade de suportar usuários simultâneos (ex.: essencial para *Black Friday*).
   - **Erros**: Taxa de erro aceitável (ex.: <0,5%). Um erro por mil requisições pode ser crítico em *e-commerce*.
   - **Saturação**: Uso de recursos (ex.: CPU/memória <70%). Acima disso, acionar *auto-scaling* para evitar *downtime*.
2. **Logs**:
   - Devem ser estruturados, respondendo: nível do erro, serviço afetado, mensagem de erro, código de erro e ID para *tracing*.
   - Logs pesquisáveis facilitam *debugging* em produção, identificando a causa raiz (*root cause*).
3. **Tracing**:
   - Rastreia o caminho de uma requisição em sistemas distribuídos (ex.: Uber com >1000 microserviços).
   - Ferramentas como Jaeger mostram latência e erros por microserviço, reduzindo o tempo de resolução.
4. **Alertas**:
   - Devem ser direcionados apenas a quem pode agir, com informações claras: tipo, severidade, condições (ex.: P95 > 500ms), ação necessária e *runbook* (documentação com passos para resolução).
   - Evitar alertas desnecessários (ex.: falha no GitHub não requer ação do time).

## SLI, SLO e SLA
- **SLI (Service Level Indicator)**: Métrica específica de desempenho (ex.: P95 < 200ms para 95% das requisições).
- **SLO (Service Level Objective)**: Meta interna de desempenho (ex.: SLI > 99,9%).
- **SLA (Service Level Agreement)**: Compromisso contratual com clientes (ex.: Spotify garante 99,5% de *uptime*). Um SLA violado pode ter implicações jurídicas.
- Esses conceitos formam uma cascata: SLIs alimentam SLOs, que sustentam SLAs, garantindo alinhamento entre desempenho técnico e expectativas do negócio.

## Caso de Estudo: Spotify
- **Contexto**: Garantir disponibilidade para >500 mil usuários ativos, evitando frustrações com *downtime* no *streaming*.
- **Métricas**:
  - *Golden Signals*: Latência, tráfego, erros e saturação monitorados para garantir desempenho.
  - SLO: 99,95% de *uptime* (0,05% de *error budget*).
  - MTTR (*Mean Time to Recovery*): 3 minutos para incidentes.
  - NPS (*Net Promoter Score*): Aumentado com alta disponibilidade.
- **Solução**: Alertas inteligentes baseados em *golden signals* detectam riscos ao SLO, permitindo respostas rápidas e mantendo a experiência do usuário.

## Passos para Implementar Observabilidade
O professor sugere um guia prático:
1. **Identificar Serviços Críticos**: Mapear as partes do sistema mais relevantes para o *core business* (ex.: APIs de pagamento em *e-commerce*).
2. **Definir Golden Signals**: Escolher métricas alinhadas ao negócio (ex.: latência para APIs, conversão para *checkouts*).
3. **Configurar Alertas Inteligentes**: Garantir visibilidade de incidentes, com *runbooks* claros para ações rápidas.
4. **Monitorar Experiência do Usuário**: Focar no que o usuário sente, não apenas no que o sistema reporta.

## Ferramentas
- **Métricas**: Prometheus, Grafana (*open source*), Datadog, New Relic (*pagos*, com suporte a métricas e análise estática).
- **Logs**: ELK Stack (Elasticsearch, Logstash, Kibana), Splunk, AWS CloudWatch.
- **Tracing**: Jaeger (*open source*, usado pelo Uber), Zipkin, AWS X-Ray.
- **Alertas**: Integrados em ferramentas como Datadog ou PagerDuty, com configurações para acionar times específicos.

## Boas Práticas
- Estruturar logs com IDs para *tracing* e contexto claro (serviço, erro, ação).
- Usar *tracing* para sistemas distribuídos, como microserviços, para mapear falhas.
- Configurar alertas com *runbooks* detalhados, evitando notificações irrelevantes.
- Alinhar métricas aos objetivos do negócio, priorizando serviços críticos.
- Monitorar a experiência do usuário final, não apenas métricas técnicas.

## Conclusão
A aula enfatiza a observabilidade como ferramenta para garantir confiabilidade e minimizar *downtime*, permitindo respostas rápidas a incidentes. Os quatro pilares (*golden signals*, logs, traces, alertas) formam a base para monitorar sistemas, enquanto SLI, SLO e SLA alinham desempenho técnico aos compromissos de negócio. O caso do Spotify ilustra como *golden signals* e alertas inteligentes mantêm 99,95% de *uptime*. Ferramentas como Prometheus, Jaeger e Datadog, combinadas com um guia prático (identificar serviços críticos, definir métricas, configurar alertas), ajudam a implementar observabilidade. A dica chave é focar na experiência do usuário, garantindo que métricas reflitam o impacto real no cliente, promovendo sistemas confiáveis e sono tranquilo para os desenvolvedores.