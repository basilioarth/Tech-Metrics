# Resumo da Aula sobre Tech Metrics (Métricas Técnicas) em Microserviços

## Introdução
A aula introduz o conceito de **métricas técnicas** (Tech Metrics), destacando sua importância para avaliar o desempenho, qualidade e saúde de sistemas em microserviços, com exemplos de empresas como Netflix, Google, Spotify e Amazon. O foco é explicar o que são métricas técnicas, como aplicá-las no dia a dia e sua relevância para justificar promoções, melhorias ou mudanças de cargo. A aula combina teoria e prática, com exemplos do mundo real, e está inserida em um módulo maior sobre métricas. Embora não haja código específico, a pasta `docs` do projeto no GitHub contém detalhes adicionais, e referências são feitas a *papers* e blogs da Netflix.

## Conceitos Fundamentais
- **Definição de Métricas Técnicas**:
  - Métricas usadas para medir melhorias em um produto, abrangendo **performance**, **qualidade**, **processo** e **saúde do sistema**.
  - **Importância**: Fornecem indicadores quantificáveis para avaliar o progresso, justificar promoções ou aumentos e identificar gargalos. Sem métricas, é difícil responder perguntas como “Como está o time?” ou demonstrar valor em cargos de liderança técnica ou DevOps.
  - **Exemplo**: Um líder técnico precisa de métricas para quantificar a saúde do sistema ou a eficiência do time, especialmente em empresas que valorizam dados (ex.: FAANG).
- **Categorias de Métricas**:
  - **Negócio**: Focam no impacto geral da empresa (ex.: tempo de resposta, *throughput*).
    - Exemplo (Spotify): Quantidade de usuários consumindo streams simultaneamente.
  - **Produto**: Relacionadas a produtos específicos dentro do negócio (ex.: métricas do *player* do Spotify).
  - **Técnicas**: Focadas em qualidade e velocidade de desenvolvimento (ex.: menos bugs, cobertura de testes robusta).
  - **Infraestrutura**: Alicerce do sistema, medindo saúde e disponibilidade (ex.: *uptime*, *error rate*).
- **Pirâmide de Métricas**:
  - **Base**: Infraestrutura (ex.: *uptime*, *error rate*).
  - **Meio**: Técnicas (ex.: *lead time*, *deployment frequency*).
  - **Topo**: Produto e Negócio (ex.: *throughput*, satisfação do usuário).
  - Cada nível suporta o anterior, com métricas de negócio sendo as mais críticas.

## Exemplos do Mundo Real
- **Netflix**:
  - Monitora mais de **1.000 métricas**, refletindo a complexidade de entregar *streaming* globalmente.
  - **Métricas-Chave**:
    1. **Deployment Frequency**:
       - A Netflix realiza milhares de *deploys* diários, usando *staged deployments* (ex.: 10% dos usuários primeiro) para testar mudanças.
       - Alta frequência indica saúde do produto e capacidade de entrega rápida.
       - Exemplo: Atualizações e *patches* são aplicados sem medo, com *rollouts* graduais para minimizar riscos.
    2. **Mean Time to Recovery (MTTR)**:
       - Mede o tempo para recuperar a aplicação após bugs ou *outages*.
       - Um *outage* de 1 hora custa ~3 milhões de dólares, tornando o MTTR crucial.
       - Reflete a eficiência na gestão de incidentes e minimização de perdas.
    3. **Change Failure Rate**:
       - Percentual de *deploys* que falham (meta: <15%).
       - Baixa taxa indica confiança dos desenvolvedores em modificar código e entregar *features* sem bugs ou *outages*.
       - Ajuda a identificar gargalos, como necessidade de refatoração ou melhorias na arquitetura.
  - **Referência**: Blogs e *papers* da Netflix detalham essas métricas, disponíveis no blog de engenharia da Netflix.

- **Outras Empresas (FAANG)**:
  - Google e outras empresas mantêm *Change Failure Rate* abaixo de 15%, com *Lead Time for Changes* e *Time to Restore Service* inferiores a 1 hora.
  - Essas métricas são consideradas “elite” (*DORA Metrics*), indicando desempenho de alto nível.

## Métricas Específicas
- **Performance**:
  - **Tempo de Resposta**: Latência para responder a requisições.
  - **Throughput**: Volume de requisições processadas por unidade de tempo.
- **Qualidade**:
  - **Taxa de Bugs**: Número de erros em produção.
  - **Cobertura de Testes**: Percentual de código coberto por testes automatizados.
- **Processo**:
  - **Lead Time**: Tempo desde a criação até a entrega de uma *feature*.
  - **Deployment Frequency**: Frequência de *deploys* em produção.
- **Saúde do Sistema**:
  - **Uptime**: Percentual de tempo que o sistema está disponível.
  - **Error Rate**: Taxa de erros em relação ao total de requisições.
- **Metas (DORA Metrics)**:
  - **Lead Time for Changes**: <1 hora.
  - **Time to Restore Service (MTTR)**: <1 hora.
  - **Deployment Frequency**: Múltiplos *deploys* por dia.
  - **Change Failure Rate**: <15%.

## Aplicação Prática
- **Como Implementar Métricas Técnicas**:
  1. **Comece Pequeno**:
     - Escolha 3 a 5 métricas iniciais relevantes para o contexto da empresa.
     - Exemplo: *Deployment Frequency*, *MTTR*, *Change Failure Rate*.
  2. **Estabeleça uma Baseline**:
     - Meça o estado atual (ex.: *uptime* atual, taxa de falhas).
     - Defina um valor de referência para comparação futura.
  3. **Defina Frequência de Avaliação**:
     - Avalie regularmente (ex.: semanal, mensal) para acompanhar tendências.
     - Use *snapshots* para verificar se as métricas estão melhorando ou piorando.
  4. **Escalone Gradualmente**:
     - Após dominar métricas iniciais, expanda para outros serviços ou áreas.
  5. **Priorize o Negócio**:
     - Escolha métricas alinhadas com os objetivos da empresa (ex.: para Spotify, *streaming* simultâneo; para e-commerce, tempo de resposta do checkout).
- **Exemplo de Implementação**:
  - **Cenário**: Uma empresa pequena quer melhorar a entrega de *features*.
  - **Passos**:
    1. Medir *Deployment Frequency* (ex.: 2 *deploys* por semana).
    2. Medir *Change Failure Rate* (ex.: 20% dos *deploys* falham).
    3. Estabelecer meta: Aumentar *Deployment Frequency* para 5 *deploys* por semana e reduzir *Change Failure Rate* para <15%.
    4. Avaliar semanalmente, ajustando processos (ex.: mais automação, testes).
- **Ferramentas**:
  - **Monitoramento**: Prometheus para coletar métricas, Grafana para visualização.
  - **Rastreamento**: OpenTelemetry para rastrear *requests* e correlacionar com *X-Request-Id*.
  - **Orquestração**: Kubernetes para gerenciar *Deployments* e escalar serviços.

## Desafios
1. **Falta de Dados Iniciais**:
   - Muitas empresas não têm métricas estabelecidas, dificultando a *baseline*.
   - **Solução**: Começar com métricas simples (ex.: *uptime*, *error rate*) e coletar dados históricos.
2. **Complexidade de Monitoramento**:
   - Rastrear milhares de métricas (como a Netflix) exige ferramentas robustas.
   - **Solução**: Usar Prometheus/Grafana e configurar alertas para métricas críticas.
3. **Alinhamento com o Negócio**:
   - Métricas técnicas podem não refletir diretamente o valor para o negócio.
   - **Solução**: Mapear métricas técnicas para métricas de negócio (ex.: *MTTR* → custo de *outages*).
4. **Cultura de Métricas**:
   - Times podem resistir a medir desempenho devido a medo de exposição.
   - **Solução**: Promover uma cultura de melhoria contínua, usando métricas para aprendizado, não punição.

## Boas Práticas
- **Escolha Métricas Relevantes**:
  - Priorize métricas alinhadas com o negócio e o produto (ex.: *throughput* para e-commerce, *uptime* para *streaming*).
- **Automatize a Coleta**:
  - Use Prometheus para métricas de infraestrutura e OpenTelemetry para rastreamento distribuído.
- **Visualize Resultados**:
  - Crie *dashboards* no Grafana para *Deployment Frequency*, *MTTR*, *Change Failure Rate*.
- **Avalie Regularmente**:
  - Defina períodos fixos (ex.: semanal) para revisar métricas e ajustar processos.
- **Integre com CI/CD**:
  - Meça *Deployment Frequency* e *Change Failure Rate* no pipeline CI/CD (ex.: Jenkins, GitHub Actions).
- **Documentação**:
  - Detalhe métricas, *baselines* e metas na pasta `docs`, com exemplos de *dashboards*.
  - Referencie *papers* da Netflix e DORA Metrics para embasamento.

## Relação com o Kubernetes
- **Conexão com o Módulo Anterior**:
  - Métricas como *Deployment Frequency* e *MTTR* são coletadas de *Deployments* no Kubernetes.
  - **ConfigMaps** armazenam configurações de monitoramento (ex.: endpoints Prometheus).
  - **Services** garantem comunicação entre sistemas de monitoramento e serviços.
  - **HPA** escala serviços com base em métricas como *throughput* ou *error rate*.
- **Ferramentas**:
  - **Lens**: Visualiza *Deployments* e métricas coletadas por Prometheus.
  - **kubectl** (ou `k`): Gerencia *Deployments* e atualizações para melhorar métricas.

## Relação com Outros Conceitos
- **Saga Pattern**:
  - Métricas como *Change Failure Rate* podem ser usadas para avaliar a eficácia de Sagas (ex.: falhas em compensações).
- **Backend for Frontend (BFF)**:
  - Métricas de *throughput* e *tempo de resposta* ajudam a avaliar a performance do BFF.
- **CQRS/Event Sourcing**:
  - Métricas como *Lead Time* medem a eficiência de pipelines Kafka que populam View Tables.
- **Observabilidade**:
  - OpenTelemetry rastreia métricas como *tempo de resposta* e *error rate*, correlacionando com *X-Request-Id*.
  - Prometheus/Grafana visualizam métricas em *dashboards*.
- **Idempotência**:
  - *Change Failure Rate* pode identificar falhas em operações idempotentes.
- **API Gateway**:
  - Métricas de *throughput* e *error rate* são coletadas no API Gateway para avaliar desempenho.

## Próximas Aulas
- **Temas Futuros**:
  - Implementação prática de métricas no projeto do GitHub.
  - Integração com frameworks (ex.: DORA Metrics) e nomenclaturas.
  - Configuração de *dashboards* em Prometheus/Grafana.
- **Objetivo**:
  - Explorar a aplicação de métricas em cenários reais.
  - Aprofundar o uso de ferramentas de monitoramento.

## Tarefa
- Escolher 1-2 métricas técnicas (ex.: *Deployment Frequency*, *MTTR*) para medir no seu time ou empresa.
- Estabelecer uma *baseline* atual e definir uma frequência de avaliação (ex.: semanal).
- Compartilhar dúvidas ou resultados nas redes sociais (@vitormlnk) para discussão na próxima aula.

## Conclusão
A aula define **métricas técnicas** como ferramentas essenciais para medir desempenho, qualidade e saúde em microserviços, com exemplos da Netflix (*Deployment Frequency*, *MTTR*, *Change Failure Rate*). Essas métricas são categorizadas em negócio, produto, técnicas e infraestrutura, formando uma pirâmide que suporta a melhoria contínua. A implementação começa com poucas métricas, uma *baseline* e avaliações regulares, escalando gradualmente. Ferramentas como Prometheus, Grafana e OpenTelemetry são recomendadas, com integração ao Kubernetes. A pasta `docs` e *papers* da Netflix fornecem mais detalhes. A tarefa é escolher métricas para aplicar, e as próximas aulas explorarão frameworks e monitoramento prático.