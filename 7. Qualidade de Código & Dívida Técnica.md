# Resumo da Aula: Qualidade de Código e Débito Técnico

## Introdução
A aula aborda a importância da qualidade de código e a gestão do débito técnico no desenvolvimento de software. O professor destaca como esses aspectos impactam a estabilidade e o sucesso de empresas, usando o caso da Night Capital como exemplo de falha catastrófica devido a um débito técnico. São apresentados indicadores de qualidade, ferramentas para análise estática e dinâmica, estratégias para priorizar débitos técnicos e práticas de grandes empresas como Google, Spotify e Netflix.

## Impacto da Qualidade de Código e Débito Técnico
- **Caso Night Capital (2018)**: Um bug em código legado, causado por *feature flags* com nomes duplicados, resultou em uma perda de 440 milhões de dólares em 45 minutos, quase levando a empresa à falência. Isso ilustra a importância de gerenciar débitos técnicos para evitar catástrofes.
- **Realidade do Mercado**: 25% do tempo de desenvolvimento é gasto com débitos técnicos, com um custo médio de 306 mil dólares por ano para cada milhão de linhas de código. Códigos legados são comuns e muitas vezes difíceis de manter devido à pressa no desenvolvimento e metodologias ágeis.

## Indicadores de Qualidade de Código
O professor enfatiza a análise estática como ponto de partida para medir a qualidade do código, destacando três indicadores principais:
- **Code Coverage**: Percentual de código coberto por testes.
  - **Spotify**: Exige 80% de cobertura para código crítico (*business logic*) e 60% para interfaces menos críticas.
  - **Netflix**: Mantém alta cobertura em serviços críticos para garantir 99,9% de *uptime*.
  - Ferramentas como SonarQube, CodeCov e Istanbul (para *front-end*) geram relatórios de cobertura, ajudando a identificar áreas com baixa testagem.
- **Cyclomatic Complexity**: Mede a quantidade de caminhos lógicos em um código (*branching*). Códigos com alta complexidade (ex.: muitas condições aninhadas) são mais propensos a bugs.
  - Regra da indústria: Limitar a complexidade a 10 por método (baseado em práticas de Google, Netflix, Spotify).
  - Exemplo: Dividir uma função complexa em funções menores e mais testáveis reduz a complexidade e facilita a manutenção.
- **Code Duplication**: Identifica trechos de código repetidos, que aumentam o risco de erros durante refatorações.
  - Limite ideal: Máximo de 5% de duplicação nos arquivos.
  - Ferramentas como SonarQube, Code Climate e JS-CPD ajudam a detectar duplicatas, especialmente em *monorepos* ou *micro-frontends*.

## Análise Estática vs. Dinâmica
- **Análise Estática**: Fornece uma visão inicial da qualidade do código, mas não captura o desempenho em produção, problemas de integração ou experiência do usuário.
- **Análise Dinâmica**: Inclui métricas como:
  - **Response Time** (P95, P99): Tempo de resposta da aplicação.
  - **Throughput**: Número de requisições processadas.
  - **Error Rate**: Quantidade de erros.
  - **Uso de Memória**: Consumo em servidores.
- **Integração**: Combinar análises estática e dinâmica em *dashboards* (ex.: Datadog) oferece uma visão holística da saúde do sistema.
- **Contexto do Negócio**: A prioridade das métricas varia pelo tipo de aplicação:
  - **APIs de Pagamento**: Foco em confiabilidade, alta cobertura de testes e baixo *error rate*, devido ao impacto financeiro de falhas.
  - **Landing Pages**: Foco em *Web Vitals* (Google), SEO e conversão, com menos ênfase em *code coverage*.

## Gerenciamento de Débito Técnico
- **Definição**: Débito técnico é o custo de manter ou corrigir código mal projetado. O Google usa uma fórmula para priorizá-lo: tempo de correção dividido pelo tempo de desenvolvimento.
  - **Farol do Google**:
    - <5%: Sistema saudável.
    - 5-10%: Requer atenção.
    - >10%: Crítico, exige ação imediata.
- **Priorização**: Identificar *hotspots* (arquivos frequentemente modificados ou com muitos bugs) para direcionar esforços de refatoração.
- **Estratégia**: Usar métricas para justificar a inclusão de débitos técnicos nos *sprints*, tanto para desenvolvedores quanto para *tech leads* e gerentes.

## Ferramentas e Práticas
- **Análise Estática**: SonarQube, Code Climate, JS-CPD (para duplicação), Istanbul (para *front-end*).
- **Análise Dinâmica**: Datadog para monitoramento em tempo real (*response time*, *error rate*, *throughput*).
- **Automação**: Integrar verificações de qualidade no CI/CD, como faz a Netflix, para manter *dashboards* atualizados.
- **Contexto**: A qualidade do código deve ser avaliada com base no impacto no negócio, combinando métricas estáticas e dinâmicas.

## Boas Práticas
- Começar com análise estática (*code coverage*, *cyclomatic complexity*, *code duplication*) para estabelecer uma *baseline*.
- Combinar com métricas dinâmicas para monitorar o desempenho em produção.
- Priorizar débitos técnicos com base em *hotspots* e impacto financeiro, usando métricas como o farol do Google.
- Evitar a busca por "números perfeitos"; focar no equilíbrio entre qualidade e contexto do negócio.
- Documentar e versionar métricas de qualidade para rastrear melhorias.

## Conclusão
A aula destaca a relevância da qualidade de código e da gestão de débitos técnicos para evitar falhas graves, como no caso da Night Capital, e melhorar a eficiência no desenvolvimento. Indicadores como *code coverage* (80% para códigos críticos), *cyclomatic complexity* (máximo 10 por método) e *code duplication* (máximo 5%) são pontos de partida para avaliar a saúde do código, complementados por métricas dinâmicas como *response time* e *error rate*. O Google oferece um modelo de priorização de débitos técnicos baseado em *hotspots* e percentuais de esforço. Ferramentas como SonarQube, Datadog e Istanbul, junto com automações no CI/CD, ajudam a monitorar e melhorar a qualidade. O professor propõe um desafio de 4 semanas para mapear essas métricas e criar uma *baseline* da saúde do sistema, reforçando a importância de alinhar qualidade técnica ao contexto de negócio.